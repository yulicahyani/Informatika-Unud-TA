{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TA-IDENTIFICATION-IDIOM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IDIOM IDENTIFICATION"
      ],
      "metadata": {
        "id": "YAQXz7GguU7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark"
      ],
      "metadata": {
        "id": "6Gsm5cN_f8sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq transformers"
      ],
      "metadata": {
        "id": "-N_XbZW5h8Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BgMDVD0h-ZD",
        "outputId": "0eb6443c-7c63-43d1-e8e1-30151f397060"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.12\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.21.5\n",
            "pandas      : 1.3.5\n",
            "torch       : 1.10.0+cu111\n",
            "transformers: 4.17.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idiom_example_df = pd.read_csv(\"/content/idiom-example.csv\")\n",
        "idiom_example_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zk8jekbAlrSH",
        "outputId": "5c7be06f-03b5-48b5-951e-33e9ef882433"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       idiom_example\n",
              "0  membanting tulang\n",
              "1         buah bibir\n",
              "2       gulung tikar\n",
              "3     banting tulang\n",
              "4         jago merah"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d493519e-e133-4bf1-8149-164048f592cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idiom_example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>membanting tulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buah bibir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gulung tikar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>banting tulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jago merah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d493519e-e133-4bf1-8149-164048f592cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d493519e-e133-4bf1-8149-164048f592cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d493519e-e133-4bf1-8149-164048f592cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random = idiom_example_df.sample(n = 5)\n",
        "idiom_example = random['idiom_example'].values\n",
        "idiom_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JNuJMzWmpnB",
        "outputId": "833fe437-91a6-476f-bd67-d546018bf38b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['lintah darat', 'bunga tidur', 'tunas bangsa', 'mental baja',\n",
              "       'gaji buta'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idiom in idiom_example:\n",
        "  print(idiom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od8qu77Wn-eY",
        "outputId": "25646813-f0ef-404a-8264-3fc71175b1ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lintah darat\n",
            "bunga tidur\n",
            "tunas bangsa\n",
            "mental baja\n",
            "gaji buta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import Stream\n",
        "import torch\n",
        "import dill\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import nltk\n",
        "import math\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch import nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes, dropout=0.3):\n",
        "    super(TextClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('cahya/bert-base-indonesian-522M')\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)\n",
        "\n",
        "\n",
        "\n",
        "class IdiomIdentification():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.class_names = ['kalimat_biasa', 'kalimat_idiom']\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('cahya/bert-base-indonesian-522M')\n",
        "    self.classification_model = TextClassifier(len(self.class_names))\n",
        "    self.classification_model.load_state_dict(torch.load('/content/drive/MyDrive/model/classification.bin'))\n",
        "    self.classification_model = self.classification_model.to(self.device)\n",
        "    self.hmm_tagger_model = dill.load(open('/content/tagger_model.dill', 'rb'))\n",
        "    self.similarity_model = torch.load('/content/drive/MyDrive/model/word_sim.bin')\n",
        "    self.truth_discovery_model = dill.load(open('/content/truth_discovery.dill', 'rb'))\n",
        "    self.idiom_example_df = pd.read_csv(\"/content/idiom-example.csv\")\n",
        "  \n",
        "  def preprocessing(self, kalimat, remove_punctuation=False, tokenization=False, lowercase=False):\n",
        "    if (remove_punctuation):\n",
        "      punc = '''!()-[]{};:'\"\\<>/?@#$%^&*_~'''\n",
        "      kalimat = kalimat.translate(str.maketrans('', '', punc))\n",
        "      kalimat = re.sub(r'/s+', ' ', kalimat).strip()\n",
        "    \n",
        "    if (tokenization):\n",
        "      word_punct_tokenizer = WordPunctTokenizer()\n",
        "      kalimat = word_punct_tokenizer.tokenize(kalimat)\n",
        "\n",
        "    if (lowercase):\n",
        "      kalimat = str.lower(kalimat)\n",
        "\n",
        "    return kalimat\n",
        "\n",
        "  def idiom_classification(self, kalimat):\n",
        "    encoded_text = self.tokenizer.encode_plus(\n",
        "      kalimat,\n",
        "      max_length=40,\n",
        "      add_special_tokens=True,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_text['input_ids'].to(self.device)\n",
        "    attention_mask = encoded_text['attention_mask'].to(self.device)\n",
        "\n",
        "    output = self.classification_model(input_ids, attention_mask)\n",
        "    _, prediction = torch.max(output, dim=1)\n",
        "\n",
        "    kategori = self.class_names[prediction]\n",
        "\n",
        "    return kategori\n",
        "  \n",
        "  def hasNumbers(self, inputString):\n",
        "    result = False\n",
        "    for char in list(inputString):\n",
        "        if(char.isdigit()):\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "  def check_tag(self, word, tag):\n",
        "    punc = list(string.punctuation)\n",
        "    punc.append('.')\n",
        "    punc.append(',')\n",
        "    punc.append('\"')\n",
        "    punc.append(\"'\")\n",
        "    \n",
        "    dates = ['Januari','Februari','Maret','April','Mei','Juni','Juli','Agustus','September','Oktober','November','Desember',\\\n",
        "            'Jan','Feb','Mar','Apr','Mei','Jun','Jul','Agt','Sep','Okt','Nov','Des',\\\n",
        "            'januari','februari','maret','april','mei','juni','juli','agustus','september','oktober','november','desember',\\\n",
        "            'Senin','Selasa','Rabu','Kamis','Jumat','Sabtu','Minggu'\n",
        "        ]\n",
        "    \n",
        "    if(word in dates):\n",
        "        tag = 'DATE'\n",
        "    \n",
        "    if(word in punc):\n",
        "        tag = 'Z'\n",
        "        \n",
        "    if(tag == 'CD' and word.isdigit()):\n",
        "        tag = 'CD'\n",
        "        \n",
        "    if(tag in ['SYM','Z','CD','MD'] and word.upper() != word and self.hasNumbers(word) == False \\\n",
        "      and word[-3:] not in ['nya','kah','lah']):\n",
        "        tag = 'NNP'\n",
        "    \n",
        "    if(tag == 'NN' and word[:1].upper() == word):\n",
        "        tag = 'NNP'\n",
        "        \n",
        "    if(tag == 'NNP' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "    \n",
        "    if(tag == 'NNP' and len(word) == 1):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    if(tag == 'FW' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    return word, tag\n",
        "\n",
        "  def pos_tagging(self, kalimat):\n",
        "    kalimat_token = self.preprocessing(kalimat, tokenization=True)\n",
        "    tagging = self.hmm_tagger_model.tag(kalimat_token)\n",
        "    final_tag = []\n",
        "    for pt in tagging:\n",
        "      w,t = self.check_tag(pt[0], pt[1])\n",
        "      final_tag.append((w,t))\n",
        "\n",
        "    return final_tag\n",
        "\n",
        "  def chunking(self, kalimat_tagged):\n",
        "    grammar = [\"CHUNK: {<NN>{2,}}\", \"CHUNK: {<NN><CD>}\", \"CHUNK: {<CD><NN>}\", \"CHUNK: {<NNP><NN>}\", \"CHUNK: {<VB><NN>}\",\n",
        "               \"CHUNK: {<VB><JJ>}\", \"CHUNK: {<VB><CD>}\", \"CHUNK: {<JJ><NN>}\", \"CHUNK: {<NN><JJ>}\", \"CHUNK: {<JJ><JJ>}\"]\n",
        "    \n",
        "    extract = []\n",
        "\n",
        "    for i in grammar:\n",
        "      cp = nltk.RegexpParser(i)\n",
        "      result = cp.parse(kalimat_tagged)\n",
        "\n",
        "      leaves = [chunk.leaves() for chunk in result if ((type(chunk) == nltk.tree.Tree) and chunk.label() == 'CHUNK')]\n",
        "      noun_bigram_groups = [list(nltk.bigrams([w for w, t in leaf])) for leaf in leaves]\n",
        "\n",
        "      ph = [' '.join(nouns) for group in noun_bigram_groups for nouns in group]\n",
        "      extract = extract + ph\n",
        "\n",
        "    return extract\n",
        "\n",
        "  def count_score_similarity(self, frasa):\n",
        "    token = frasa.split()\n",
        "    similarity_score = self.similarity_model.predict(token[0], token[1])[0][0]\n",
        "\n",
        "    random = self.idiom_example_df.sample(n = 5)\n",
        "    idiom_example = random['idiom_example'].values\n",
        "    \n",
        "    for idiom in idiom_example:\n",
        "      similarity_score = similarity_score + self.similarity_model.predict(frasa, idiom)[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "  def similarity(self, frasa):\n",
        "    frasa_pred = []\n",
        "    if len(frasa) == 0:\n",
        "      frasa_pred = []\n",
        "    else:\n",
        "      for f in frasa:\n",
        "        sim_score = self.count_score_similarity(f)\n",
        "        if sim_score > 0.5:\n",
        "          frasa_pred.append(f)\n",
        "\n",
        "    return frasa_pred\n",
        "\n",
        "  def validasi(self, frasa):\n",
        "    frasa_idiom = []\n",
        "    for f in frasa:\n",
        "      f = self.preprocessing(f, lowercase=True)\n",
        "      kategori = self.truth_discovery_model.predict([f])[0]\n",
        "      if kategori == 1:\n",
        "        frasa_idiom.append(f)\n",
        "    \n",
        "    return frasa_idiom\n",
        "\n",
        "  def _predict(self, kalimat):\n",
        "    kalimat = self.preprocessing(kalimat, remove_punctuation=True)\n",
        "    klasifikasi = self.idiom_classification(kalimat)\n",
        "    \n",
        "    if (klasifikasi == 'kalimat_biasa'):\n",
        "      frasa = 'none'\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "    else:\n",
        "      postag = self.pos_tagging(kalimat)\n",
        "      frasa_chunk = self.chunking(postag)\n",
        "      frasa_pred = self.similarity(frasa_chunk)\n",
        "      frasa_idiom = self.validasi(frasa_pred)\n",
        "      if len(frasa_idiom) == 0:\n",
        "        frasa = 'none'\n",
        "      else:\n",
        "        frasa = frasa_idiom[0]\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "\n",
        "    return hasil\n",
        "\n",
        "  def predict(self, X):\n",
        "    predicted_result = [self._predict(x) for x in X]\n",
        "    return predicted_result"
      ],
      "metadata": {
        "id": "3Jr4436rjhrV"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/idiom-ta-kalimat-dataset.csv\", encoding = 'unicode_escape')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9bxf_ni56YVF",
        "outputId": "9991a0e9-0549-453b-e376-aec391f4610f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             kalimat       kategori  \\\n",
              "0  Orang tua itu rela membanting tulang demi meny...  kalimat_idiom   \n",
              "1  Rusmi jadi buah bibir setelah menjuarai lomba ...  kalimat_idiom   \n",
              "2  Gara-gara pandemi covid-19 usaha Doyok harus g...  kalimat_idiom   \n",
              "3  Saat pandemi ini Esti harus banting tulang unt...  kalimat_idiom   \n",
              "4  Karena pandemi Covid-19, restoran Pak Hilman a...  kalimat_idiom   \n",
              "\n",
              "         frasa idiom validasi  \\\n",
              "0  membanting tulang    idiom   \n",
              "1         buah bibir    idiom   \n",
              "2       gulung tikar    idiom   \n",
              "3     banting tulang    idiom   \n",
              "4       gulung tikar    idiom   \n",
              "\n",
              "                                              sumber  \n",
              "0  https://tirto.id/pengertian-idiom-dalam-bahasa...  \n",
              "1  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "2  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "3  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "4  https://xerpihan.id/blog/770/apa-itu-idiom-pen...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-931a9c47-90d9-4c09-8370-79116d05d556\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kalimat</th>\n",
              "      <th>kategori</th>\n",
              "      <th>frasa idiom</th>\n",
              "      <th>validasi</th>\n",
              "      <th>sumber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Orang tua itu rela membanting tulang demi meny...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>membanting tulang</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://tirto.id/pengertian-idiom-dalam-bahasa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rusmi jadi buah bibir setelah menjuarai lomba ...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>buah bibir</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gara-gara pandemi covid-19 usaha Doyok harus g...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>gulung tikar</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saat pandemi ini Esti harus banting tulang unt...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>banting tulang</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karena pandemi Covid-19, restoran Pak Hilman a...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>gulung tikar</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://xerpihan.id/blog/770/apa-itu-idiom-pen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-931a9c47-90d9-4c09-8370-79116d05d556')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-931a9c47-90d9-4c09-8370-79116d05d556 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-931a9c47-90d9-4c09-8370-79116d05d556');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = IdiomIdentification()"
      ],
      "metadata": {
        "id": "_DQjLvlh4u5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi"
      ],
      "metadata": {
        "id": "p2Jtujo2w9vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "list_n_data = []\n",
        " \n",
        "for n in range(1,11):\n",
        "    list_n_data.append(n*200)\n",
        "\n",
        "acc = []\n",
        "precission = []\n",
        "recall = []\n",
        "f1score = []\n",
        "\n",
        "for n_data in list_n_data:\n",
        "\n",
        "  data = df.sample(n = n_data)\n",
        "  X_kalimat = data['kalimat'].values.tolist()\n",
        "  y_frasa = data['frasa idiom'].values.tolist()\n",
        "  y_validasi = data['validasi'].values.tolist()\n",
        "  y_validasi = [1 if i=='idiom' else 0 for i in y_validasi]\n",
        "\n",
        "  predictions = model.predict(X_kalimat)\n",
        "\n",
        "  idiom_predicted = [predictions[x][2] for x in range(len(predictions))]\n",
        "  y_predicted = ['idiom' if y_frasa[i]==idiom_predicted[i] and idiom_predicted[i]!='none'  else 'bukan_idiom' for i in range(len(idiom_predicted))]\n",
        "  y_predicted = [1 if i=='idiom' else 0 for i in y_predicted]\n",
        "\n",
        "  val_acc = accuracy_score(y_validasi, y_predicted)\n",
        "  acc.append(val_acc)\n",
        "\n",
        "  val_precission = precision_score(y_validasi, y_predicted)\n",
        "  precission.append(val_precission)\n",
        "\n",
        "  val_recall = recall_score(y_validasi, y_predicted)\n",
        "  recall.append(val_recall)\n",
        "\n",
        "  val_f1score = f1_score(y_validasi, y_predicted)\n",
        "  f1score.append(val_f1score)\n",
        "\n",
        "  print('-' * 10)\n",
        "  print(f'accuracy {val_acc}')\n",
        "  print(f'precission {val_precission}')\n",
        "  print(f'recall {val_recall}')\n",
        "  print(f'f1score {val_f1score}')\n",
        "\n",
        "\n",
        "mean_acc = sum(acc) / len(acc)\n",
        "mean_precission = sum(precission) / len(precission)\n",
        "mean_recall = sum(recall) / len(recall)\n",
        "mean_f1score = sum(f1score) / len(f1score)\n",
        "\n",
        "print('-' * 10)\n",
        "print(f\"Mean-Accuracy: {mean_acc}\")\n",
        "print(f\"Mean-Precision: {mean_precission}\")\n",
        "print(f\"Mean-Recall: {mean_recall}\")\n",
        "print(f\"Mean-F1score: {mean_f1score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F-tmIoKw8Kw",
        "outputId": "e5bf5516-3902-416d-d3bb-9f5750bd8f69"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "accuracy 0.81\n",
            "precission 1.0\n",
            "recall 0.62\n",
            "f1score 0.7654320987654321\n",
            "----------\n",
            "accuracy 0.81\n",
            "precission 1.0\n",
            "recall 0.6161616161616161\n",
            "f1score 0.7625\n",
            "----------\n",
            "accuracy 0.7983333333333333\n",
            "precission 1.0\n",
            "recall 0.6134185303514377\n",
            "f1score 0.7603960396039604\n",
            "----------\n",
            "accuracy 0.805\n",
            "precission 1.0\n",
            "recall 0.6276849642004774\n",
            "f1score 0.7712609970674487\n",
            "----------\n",
            "accuracy 0.806\n",
            "precission 1.0\n",
            "recall 0.6088709677419355\n",
            "f1score 0.7568922305764411\n",
            "----------\n",
            "accuracy 0.8125\n",
            "precission 1.0\n",
            "recall 0.6179966044142614\n",
            "f1score 0.763903462749213\n",
            "----------\n",
            "accuracy 0.8142857142857143\n",
            "precission 1.0\n",
            "recall 0.6198830409356725\n",
            "f1score 0.7653429602888087\n",
            "----------\n",
            "accuracy 0.809375\n",
            "precission 1.0\n",
            "recall 0.6158690176322418\n",
            "f1score 0.7622759158222914\n",
            "----------\n",
            "accuracy 0.8133333333333334\n",
            "precission 1.0\n",
            "recall 0.6254180602006689\n",
            "f1score 0.7695473251028807\n",
            "----------\n",
            "accuracy 0.8115\n",
            "precission 1.0\n",
            "recall 0.623\n",
            "f1score 0.7677141096734442\n",
            "----------\n",
            "Mean-Accuracy: 0.8090327380952381\n",
            "Mean-Precision: 1.0\n",
            "Mean-Recall: 0.6188302801638311\n",
            "Mean-F1score: 0.7645265139649922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeks = list(range(1, 11))\n",
        "\n",
        "jml_data_df = pd.DataFrame(list_n_data, index=indeks, columns=['Jumlah Data'])\n",
        "acc_df = pd.DataFrame(acc, index=indeks, columns=['Accuracy'])\n",
        "precission_df = pd.DataFrame(precission, index=indeks, columns=['Precission'])\n",
        "recall_df = pd.DataFrame(recall, index=indeks, columns=['Recall'])\n",
        "f1score_df = pd.DataFrame(f1score, index=indeks, columns=['F1-score'])\n",
        "\n",
        "list_mean = [['', mean_acc, mean_precission, mean_recall, mean_f1score]]\n",
        "mean_df = pd.DataFrame(list_mean,index =['Rata-Rata'], columns =['Jumlah Data','Accuracy','Precission','Recall', 'F1-score'])\n",
        "\n",
        "evaluasi = pd.concat([jml_data_df, acc_df, precission_df, recall_df, f1score_df], axis=1)\n",
        "evaluasi_fix = pd.concat([evaluasi, mean_df], axis=0)\n",
        "evaluasi_fix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JLNNwyO6-nI9",
        "outputId": "b831621f-3d09-478d-c97d-ceb7c1aa4398"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Jumlah Data  Accuracy  Precission    Recall  F1-score\n",
              "1                 200  0.810000         1.0  0.620000  0.765432\n",
              "2                 400  0.810000         1.0  0.616162  0.762500\n",
              "3                 600  0.798333         1.0  0.613419  0.760396\n",
              "4                 800  0.805000         1.0  0.627685  0.771261\n",
              "5                1000  0.806000         1.0  0.608871  0.756892\n",
              "6                1200  0.812500         1.0  0.617997  0.763903\n",
              "7                1400  0.814286         1.0  0.619883  0.765343\n",
              "8                1600  0.809375         1.0  0.615869  0.762276\n",
              "9                1800  0.813333         1.0  0.625418  0.769547\n",
              "10               2000  0.811500         1.0  0.623000  0.767714\n",
              "Rata-Rata              0.809033         1.0  0.618830  0.764527"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbf80627-6ff3-46f1-9f65-f61ec139a63a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Jumlah Data</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precission</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.765432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>400</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.616162</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>600</td>\n",
              "      <td>0.798333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.613419</td>\n",
              "      <td>0.760396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>800</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.627685</td>\n",
              "      <td>0.771261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.608871</td>\n",
              "      <td>0.756892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1200</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.617997</td>\n",
              "      <td>0.763903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1400</td>\n",
              "      <td>0.814286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.619883</td>\n",
              "      <td>0.765343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1600</td>\n",
              "      <td>0.809375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.615869</td>\n",
              "      <td>0.762276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1800</td>\n",
              "      <td>0.813333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.625418</td>\n",
              "      <td>0.769547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2000</td>\n",
              "      <td>0.811500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.623000</td>\n",
              "      <td>0.767714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rata-Rata</th>\n",
              "      <td></td>\n",
              "      <td>0.809033</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.618830</td>\n",
              "      <td>0.764527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf80627-6ff3-46f1-9f65-f61ec139a63a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbf80627-6ff3-46f1-9f65-f61ec139a63a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbf80627-6ff3-46f1-9f65-f61ec139a63a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = model.predict(['Andi dikenal sebagai kutu buku.', 'Andi selalu menjadi anak bawang di kelasnya.'])"
      ],
      "metadata": {
        "id": "XE8___J949ZD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSyJvTUODZyG",
        "outputId": "d2706b3e-becc-419f-d9af-8a81ce1a7a87"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Andi dikenal sebagai kutu buku.', 'kalimat_idiom', 'kutu buku'), ('Andi selalu menjadi anak bawang di kelasnya.', 'kalimat_idiom', 'anak bawang')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frasa = [hasil[x][2] for x in range(len(hasil))]\n",
        "frasa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csurZHWCPzH8",
        "outputId": "df049026-2839-435f-90f5-f2e5ca14170f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kutu buku', 'anak bawang']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.sample(n = 10)"
      ],
      "metadata": {
        "id": "AL-CoiTBLkTL"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_kalimat = df1['kalimat'].values.tolist()\n",
        "y_frasa = df1['frasa idiom'].values.tolist()\n",
        "y_validasi = df1['validasi'].values.tolist()"
      ],
      "metadata": {
        "id": "bN4Q4lI7D_YO"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_kalimat[:5], y_frasa[:5], y_validasi[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2G06owAVXwD",
        "outputId": "0a290cf1-9bcf-490e-928a-4d086ef28b7b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Kucing itu tengah melompati pagar.',\n",
              "  'Pamanku datang dari Surabaya dan membawa buah tangan.',\n",
              "  'Di zaman digitalisasi ini, banyak sekali kabar burung yang beredar di media sosial.',\n",
              "  'Adik melihat kereta.',\n",
              "  'Kaca mata tebalnya menunjukkan bahwa ia kutu buku.\\xa0'],\n",
              " ['none', 'buah tangan', 'kabar burung', 'none', 'kutu buku'],\n",
              " ['bukan_idiom', 'idiom', 'idiom', 'bukan_idiom', 'idiom'])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_kalimat)"
      ],
      "metadata": {
        "id": "--CCLbwBRT5p"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gStbUx-nSmr6",
        "outputId": "dd2d675d-069b-44ae-d9f5-0abdd530fb65"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Kucing itu tengah melompati pagar.', 'kalimat_biasa', 'none'),\n",
              " ('Pamanku datang dari Surabaya dan membawa buah tangan.',\n",
              "  'kalimat_idiom',\n",
              "  'buah tangan'),\n",
              " ('Di zaman digitalisasi ini, banyak sekali kabar burung yang beredar di media sosial.',\n",
              "  'kalimat_idiom',\n",
              "  'kabar burung'),\n",
              " ('Adik melihat kereta.', 'kalimat_biasa', 'none'),\n",
              " ('Kaca mata tebalnya menunjukkan bahwa ia kutu buku.',\n",
              "  'kalimat_idiom',\n",
              "  'none')]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idiom_predicted = [predictions[x][2] for x in range(len(predictions))]\n",
        "idiom_predicted[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cDU9GvXzn0",
        "outputId": "84425133-aa9c-4d8f-b4d0-567ed08c8df2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['none', 'buah tangan', 'kabar burung', 'none', 'none']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = ['idiom' if y_frasa[i]==idiom_predicted[i] and idiom_predicted[i]!='none'  else 'bukan_idiom' for i in range(len(idiom_predicted))]\n",
        "y_predicted[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sBY0UQcyi8K",
        "outputId": "40efa0c0-6432-4fc6-e2cf-40f0a60ddee2"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bukan_idiom', 'idiom', 'idiom', 'bukan_idiom', 'bukan_idiom']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_validasi = [1 if i=='idiom' else 0 for i in y_validasi]\n",
        "y_predicted = [1 if i=='idiom' else 0 for i in y_predicted]\n",
        "\n",
        "y_validasi[:5], y_predicted[:5]"
      ],
      "metadata": {
        "id": "SmA8hzbAwQ5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "label_name = ['bukan_idiom', 'idiom']\n",
        "print('Accuracy:', accuracy_score(y_validasi, y_predicted))\n",
        "print('Precision:', precision_score(y_validasi, y_predicted))\n",
        "print('Recall:', recall_score(y_validasi, y_predicted))\n",
        "print('F1-score:', f1_score(y_validasi, y_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i06hsFH8XoOg",
        "outputId": "fa1416d3-22e7-4b71-ddac-a77be8602ff5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n",
            "Precision: 1.0\n",
            "Recall: 0.8\n",
            "F1-score: 0.888888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ypqq44DWw3oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "89PYMlhTw3cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPERIMEN"
      ],
      "metadata": {
        "id": "ZQT7vUVcDbxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_idiom_exmp = df['frasa idiom'].unique()\n",
        "idiom_exmp_df = pd.DataFrame(list_idiom_exmp, columns =['idiom_example'])\n",
        "idiom_exmp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fNup-rq2jjtQ",
        "outputId": "fb502ee5-2a79-4def-d76a-fd128f8cd7fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         idiom_example\n",
              "0    membanting tulang\n",
              "1           buah bibir\n",
              "2         gulung tikar\n",
              "3       banting tulang\n",
              "4           jago merah\n",
              "..                 ...\n",
              "164       tunas bangsa\n",
              "165       menusuk hati\n",
              "166      banting setir\n",
              "167       bunga bangsa\n",
              "168               none\n",
              "\n",
              "[169 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be0735ae-8f17-447e-a9d6-546617fb25c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idiom_example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>membanting tulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buah bibir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gulung tikar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>banting tulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jago merah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>tunas bangsa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>menusuk hati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>banting setir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>bunga bangsa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>169 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be0735ae-8f17-447e-a9d6-546617fb25c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be0735ae-8f17-447e-a9d6-546617fb25c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be0735ae-8f17-447e-a9d6-546617fb25c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idiom_exmp_df.to_csv('idiom-example.csv', index=False)"
      ],
      "metadata": {
        "id": "zlpJXeDyk5si"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "import string\n",
        "from torch import clamp\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "class TokenSimilarity:\n",
        "\n",
        "    def load_pretrained(self, from_pretrained:str=\"indobenchmark/indobert-base-p1\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(from_pretrained)\n",
        "        self.model = AutoModel.from_pretrained(from_pretrained)\n",
        "        \n",
        "    def __cleaning(self, text:str):\n",
        "        # clear punctuations\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        # clear multiple spaces\n",
        "        text = re.sub(r'/s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "        \n",
        "    def __process(self, first_token:str, second_token:str):\n",
        "        inputs = self.tokenizer([first_token, second_token],\n",
        "                                max_length=self.max_length,\n",
        "                                truncation=self.truncation,\n",
        "                                padding=self.padding,\n",
        "                                return_tensors='pt')\n",
        "\n",
        "        attention = inputs.attention_mask\n",
        "\n",
        "        outputs = self.model(**inputs)\n",
        "\n",
        "        # get the weights from the last layer as embeddings\n",
        "        embeddings = outputs[0] # when used in older transformers version\n",
        "        # embeddings = outputs.last_hidden_state # when used in newer one\n",
        "\n",
        "        # add more dimension then expand tensor\n",
        "        # to match embeddings shape by duplicating its values by rows\n",
        "        mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
        "\n",
        "        masked_embeddings = embeddings * mask\n",
        "        \n",
        "        # MEAN POOLING FOR 2ND DIMENSION\n",
        "        # first, get sums by 2nd dimension\n",
        "        # second, get counts of 2nd dimension\n",
        "        # third, calculate the mean, i.e. sums/counts\n",
        "        summed = masked_embeddings.sum(1)\n",
        "        counts = clamp(mask.sum(1), min=1e-9)\n",
        "        mean_pooled = summed/counts\n",
        "\n",
        "        # return mean pooling as numpy array\n",
        "        return mean_pooled.detach().numpy()\n",
        "        \n",
        "    def predict(self, first_token:str, second_token:str,\n",
        "                return_as_embeddings:bool=False, max_length:int=16,\n",
        "                truncation:bool=True, padding:str=\"max_length\"):\n",
        "        self.max_length = max_length\n",
        "        self.truncation = truncation\n",
        "        self.padding = padding\n",
        "\n",
        "        first_token = self.__cleaning(first_token)\n",
        "        second_token = self.__cleaning(second_token)\n",
        "\n",
        "        mean_pooled_arr = self.__process(first_token, second_token)\n",
        "        if return_as_embeddings:\n",
        "            return mean_pooled_arr\n",
        "\n",
        "        # calculate similarity\n",
        "        similarity = cosine_similarity([mean_pooled_arr[0]], [mean_pooled_arr[1]])\n",
        "\n",
        "        return similarity\n",
        "\n",
        "\n",
        "# word_sim = torch.load('/content/content/model/word_sim.bin')"
      ],
      "metadata": {
        "id": "XJfEUOfHkojT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1VoS18t95hKd7XvbtddC8jvYmRHI7TXYG',\n",
        "                                    dest_path='content/model.zip',\n",
        "                                    unzip=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue6SxmJp0Nkp",
        "outputId": "3784bfc5-4d73-4f10-c730-4011e279f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1VoS18t95hKd7XvbtddC8jvYmRHI7TXYG into content/model.zip... Done.\n",
            "Unzipping..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google_drive_downloader/google_drive_downloader.py:78: UserWarning: Ignoring `unzip` since \"1VoS18t95hKd7XvbtddC8jvYmRHI7TXYG\" does not look like a valid zip file\n",
            "  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers"
      ],
      "metadata": {
        "id": "iJ_a_azxzZGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "k__Bqsnal5si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import Stream\n",
        "import torch\n",
        "import dill\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import nltk\n",
        "import math\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "class IdiomIdentification():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.classification_model = torch.load('/content/content/model/classification_model.bin')\n",
        "    self.hmm_tagger_model = dill.load(open('/content/tagger_model.dill', 'rb'))\n",
        "    self.similarity_model = torch.load('/content/content/model/word_sim.bin')\n",
        "    self.truth_discovery_model = dill.load(open('/content/truth_discovery.dill', 'rb'))\n",
        "\n",
        "  def idiom_classification(self, kalimat):\n",
        "    class_names = ['kalimat_biasa', 'kalimat_idiom']\n",
        "    predictions = self.classification_model.predict([kalimat])\n",
        "    kategori = class_names[int(predictions[0])]\n",
        "    return kategori\n",
        "  \n",
        "  def hasNumbers(inputString):\n",
        "    result = False\n",
        "    for char in list(inputString):\n",
        "        if(char.isdigit()):\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "  def check_tag(self, word, tag):\n",
        "    punc = list(string.punctuation)\n",
        "    punc.append('.')\n",
        "    punc.append(',')\n",
        "    punc.append('\"')\n",
        "    punc.append(\"'\")\n",
        "    \n",
        "    dates = ['Januari','Februari','Maret','April','Mei','Juni','Juli','Agustus','September','Oktober','November','Desember',\\\n",
        "            'Jan','Feb','Mar','Apr','Mei','Jun','Jul','Agt','Sep','Okt','Nov','Des',\\\n",
        "            'januari','februari','maret','april','mei','juni','juli','agustus','september','oktober','november','desember',\\\n",
        "            'Senin','Selasa','Rabu','Kamis','Jumat','Sabtu','Minggu'\n",
        "        ]\n",
        "    \n",
        "    if(word in dates):\n",
        "        tag = 'DATE'\n",
        "    \n",
        "    if(word in punc):\n",
        "        tag = 'Z'\n",
        "        \n",
        "    if(tag == 'CD' and word.isdigit()):\n",
        "        tag = 'CD'\n",
        "        \n",
        "    if(tag in ['SYM','Z','CD','MD'] and word.upper() != word and self.hasNumbers(word) == False \\\n",
        "      and word[-3:] not in ['nya','kah','lah']):\n",
        "        tag = 'NNP'\n",
        "    \n",
        "    if(tag == 'NN' and word[:1].upper() == word):\n",
        "        tag = 'NNP'\n",
        "        \n",
        "    if(tag == 'NNP' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "    \n",
        "    if(tag == 'NNP' and len(word) == 1):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    if(tag == 'FW' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    return word, tag\n",
        "\n",
        "  def pos_tagging(self, kalimat):\n",
        "    word_punct_tokenizer = WordPunctTokenizer()\n",
        "    kalimat_token = word_punct_tokenizer.tokenize(kalimat)\n",
        "    tagging = self.hmm_tagger_model.tag(kalimat_token)\n",
        "    final_tag = []\n",
        "    for pt in tagging:\n",
        "      w,t = self.check_tag(pt[0], pt[1])\n",
        "      final_tag.append((w,t))\n",
        "\n",
        "    return final_tag\n",
        "\n",
        "  def chunking(self, kalimat_tagged):\n",
        "    grammar = [\"CHUNK: {<NN>{2,}}\", \"CHUNK: {<NN><CD>}\", \"CHUNK: {<CD><NN>}\", \"CHUNK: {<NNP><NN>}\", \"CHUNK: {<VB><NN>}\",\n",
        "               \"CHUNK: {<VB><JJ>}\", \"CHUNK: {<VB><CD>}\", \"CHUNK: {<JJ><NN>}\", \"CHUNK: {<NN><JJ>}\", \"CHUNK: {<JJ><JJ>}\"]\n",
        "    \n",
        "    extract = []\n",
        "\n",
        "    for i in grammar:\n",
        "      cp = nltk.RegexpParser(i)\n",
        "      result = cp.parse(kalimat_tagged)\n",
        "\n",
        "      leaves = [chunk.leaves() for chunk in result if ((type(chunk) == nltk.tree.Tree) and chunk.label() == 'CHUNK')]\n",
        "      noun_bigram_groups = [list(nltk.bigrams([w for w, t in leaf])) for leaf in leaves]\n",
        "\n",
        "      ph = [' '.join(nouns) for group in noun_bigram_groups for nouns in group]\n",
        "      extract = extract + ph\n",
        "\n",
        "    return extract\n",
        "\n",
        "  def count_score_similarity(self, frasa):\n",
        "    token = frasa.split()\n",
        "    similarity_score = self.similarity_model.predict(token[0], token[1])[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "  def similarity(self, frasa):\n",
        "    frasa_pred = []\n",
        "    for f in frasa:\n",
        "      sim_score = self.count_score_similarity(f)\n",
        "      if sim_score > 0.5:\n",
        "        frasa_pred.append(f)\n",
        "\n",
        "    return frasa_pred\n",
        "\n",
        "  def validasi(self, frasa):\n",
        "    frasa_idiom = []\n",
        "    for f in frasa:\n",
        "      kategori = self.truth_discovery_model.predict([f])[0]\n",
        "      if kategori == 1:\n",
        "        frasa_idiom.append(f)\n",
        "    \n",
        "    return frasa_idiom\n",
        "\n",
        "  def _predict(self, kalimat):\n",
        "    klasifikasi = self.idiom_classification(kalimat)\n",
        "    \n",
        "    if (klasifikasi == 'kalimat_biasa'):\n",
        "      frasa = 'none'\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "    else:\n",
        "      postag = self.pos_tagging(kalimat)\n",
        "      frasa_chunk = self.chunking(postag)\n",
        "      frasa_pred = self.similarity(frasa_chunk)\n",
        "      frasa_idiom = self.validasi(frasa_pred)\n",
        "      if len(frasa_idiom) == 0:\n",
        "        frasa = 'none'\n",
        "      else:\n",
        "        frasa = frasa_idiom[0]\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "\n",
        "    return hasil\n",
        "\n",
        "  def predict(self, X):\n",
        "    predicted_result = [self._predict(x) for x in X]\n",
        "    return predicted_result"
      ],
      "metadata": {
        "id": "b9xjmC50NV9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token1 = 'kutu buku'\n",
        "token2 = 'Anak kutu buku itu menjuarai lomba matematika.'\n",
        "\n",
        "word_punct_tokenizer = WordPunctTokenizer()\n",
        "kalimat_token = word_punct_tokenizer.tokenize(token2)\n",
        "\n",
        "similarity_score1 = 0\n",
        "# for w in kalimat_token:\n",
        "#   print(word_sim.predict(token1, w)[0][0])\n",
        "#   similarity_score1 = similarity_score1 + word_sim.predict(token1, w)[0][0]\n",
        "\n",
        "similarity_score1 = similarity_score1 + word_sim.predict(token1, token2)[0][0]\n",
        "\n",
        "# token = token1.split()\n",
        "# similarity_score1 = similarity_score1 + word_sim.predict(token[0], token[1])[0][0]\n",
        "\n",
        "similarity_score1\n"
      ],
      "metadata": {
        "id": "BhYxSSLpaqgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruWcphvmuPcm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "classification_model = torch.load('/content/content/model/classification_model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['kalimat_biasa', 'kalimat_idiom']\n",
        "predictions= classification_model.predict(['Anak kutu buku itu menjuarai lomba matematika.'])\n",
        "class_names[int(predictions[0])]"
      ],
      "metadata": {
        "id": "yvPogRNx_C73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\\\n",
        "import dill\n",
        "with open('/content/tagger_model.dill', 'rb') as f:\n",
        "    hmm_tagger = dill.load(f)"
      ],
      "metadata": {
        "id": "IJA_5IG_dcRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "kalimat = \"Anak kutu buku itu menjuarai lomba matematika.\"\n",
        "word_punct_tokenizer = WordPunctTokenizer()\n",
        "kalimat_token = word_punct_tokenizer.tokenize(kalimat)\n",
        "pos_tagging = hmm_tagger.tag(kalimat_token)\n",
        "pos_tagging"
      ],
      "metadata": {
        "id": "j4ccmen9Fy--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk(kalimat_tagged):\n",
        "  grammar = [\"CHUNK: {<NN>{2,}}\", \"CHUNK: {<NN><CD>}\", \"CHUNK: {<CD><NN>}\", \"CHUNK: {<NNP><NN>}\", \"CHUNK: {<VB><NN>}\",\n",
        "               \"CHUNK: {<VB><JJ>}\", \"CHUNK: {<VB><CD>}\", \"CHUNK: {<JJ><NN>}\", \"CHUNK: {<NN><JJ>}\", \"CHUNK: {<JJ><JJ>}\"]\n",
        "    \n",
        "  extract = []\n",
        "\n",
        "  for i in grammar:\n",
        "    cp = nltk.RegexpParser(i)\n",
        "    result = cp.parse(kalimat_tagged)\n",
        "\n",
        "    leaves = [chunk.leaves() for chunk in result if ((type(chunk) == nltk.tree.Tree) and chunk.label() == 'CHUNK')]\n",
        "    noun_bigram_groups = [list(nltk.bigrams([w for w, t in leaf])) for leaf in leaves]\n",
        "\n",
        "    ph = [' '.join(nouns) for group in noun_bigram_groups for nouns in group]\n",
        "    extract = extract + ph\n",
        "\n",
        "  return extract"
      ],
      "metadata": {
        "id": "DyFvLyNM6Bgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frasa = chunk(pos_tagging)\n",
        "frasa"
      ],
      "metadata": {
        "id": "fTLhQ_Ex6H3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_tagged = []\n",
        "for pt in pos_tagging:\n",
        "  w,t = xcheck_tag(pt[0], pt[1])\n",
        "  final_tagged.append((w,t))\n",
        "\n",
        "final_tagged"
      ],
      "metadata": {
        "id": "gjks3BCle8lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "import dill\n",
        "with open('/content/truth_discovery.dill', 'rb') as f:\n",
        "    td_model = dill.load(f)"
      ],
      "metadata": {
        "id": "583L_cNxgdWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_file = open('/content/truth_discovery.dill', 'rb')\n",
        "trainer_object = dill.load(open('/content/truth_discovery.dill', 'rb'))"
      ],
      "metadata": {
        "id": "JLx-YJD_RLzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "pred = trainer_object.predict(['anak bawang'])[0]\n",
        "pred"
      ],
      "metadata": {
        "id": "6SAIhsXy9xMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token1 = 'meja'\n",
        "token2 = 'hijau'\n",
        "similarity_score1 = word_sim.predict(token1, token2)\n",
        "similarity_score1"
      ],
      "metadata": {
        "id": "y68Y7oa4Hvg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token1 = 'anak bawang'\n",
        "token2 = 'Andi selalu menjadi anak bawang di kelasnya.'\n",
        "similarity_score1 = word_sim.predict(token1, token2)\n",
        "similarity_score1"
      ],
      "metadata": {
        "id": "7qHJwqMMXLyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token1 = 'anak bawang'\n",
        "token2 = 'bawang'\n",
        "similarity_score1 = word_sim.predict(token1, token2)\n",
        "similarity_score1\n",
        "# \"Anak kutu buku itu menjuarai lomba matematika.\"\n",
        "\n",
        "token = token1.split()\n",
        "token"
      ],
      "metadata": {
        "id": "_3kd_TSkWZpj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}