{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TA_IDENTIFICATION_IDIOM (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IDIOM IDENTIFICATION"
      ],
      "metadata": {
        "id": "YAQXz7GguU7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARY"
      ],
      "metadata": {
        "id": "3pNqc6Lh7lCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark"
      ],
      "metadata": {
        "id": "6Gsm5cN_f8sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq transformers"
      ],
      "metadata": {
        "id": "-N_XbZW5h8Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "metadata": {
        "id": "0hSJn7ixk3AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Identifikasi"
      ],
      "metadata": {
        "id": "tDL6gI0V9DGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from torch import clamp\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "MODEL_NAME = 'cahya/bert-base-indonesian-522M'\n",
        "\n",
        "class TokenSimilarity:\n",
        "\n",
        "    def __init__(self, from_pretrained:str=MODEL_NAME):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(from_pretrained)\n",
        "        self.model = AutoModel.from_pretrained(from_pretrained)\n",
        "        \n",
        "    def __process(self, first_token:str, second_token:str):\n",
        "        inputs = self.tokenizer([first_token, second_token],\n",
        "                                max_length=self.max_length,\n",
        "                                truncation=self.truncation,\n",
        "                                padding=self.padding,\n",
        "                                return_tensors='pt')\n",
        "\n",
        "        attention = inputs.attention_mask\n",
        "        outputs = self.model(**inputs)\n",
        "        embeddings = outputs[0]\n",
        "        mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
        "        masked_embeddings = embeddings * mask\n",
        "        \n",
        "        summed = masked_embeddings.sum(1)\n",
        "        counts = clamp(mask.sum(1), min=1e-9)\n",
        "        mean_pooled = summed/counts\n",
        "\n",
        "        return mean_pooled.detach().numpy()\n",
        "        \n",
        "    def predict(self, first_token:str, second_token:str, max_length:int=40,\n",
        "                truncation:bool=True, padding:str=\"max_length\"):\n",
        "        self.max_length = max_length\n",
        "        self.truncation = truncation\n",
        "        self.padding = padding\n",
        "\n",
        "        mean_pooled_arr = self.__process(first_token, second_token)\n",
        "        similarity = cosine_similarity([mean_pooled_arr[0]], [mean_pooled_arr[1]])\n",
        "\n",
        "        return similarity"
      ],
      "metadata": {
        "id": "XJfEUOfHkojT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import Stream\n",
        "import torch\n",
        "import dill\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import nltk\n",
        "import math\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch import nn\n",
        "\n",
        "MODEL_NAME = 'cahya/bert-base-indonesian-522M'\n",
        "\n",
        "class  BertClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes, dropout=0.3):\n",
        "    super(BertClassifier, self).__init__()\n",
        "    self.bert = self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids=token_type_ids,\n",
        "      return_dict=False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    logits = self.out(output)\n",
        "    classifier = torch.nn.functional.softmax(logits, dim=1)\n",
        "    _, pred = torch.max(classifier, dim=1)\n",
        "    return logits, pred\n",
        "\n",
        "\n",
        "class IdiomIdentification():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.class_names = ['kalimat_biasa', 'kalimat_idiom']\n",
        "    self.tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "    self.classification_model = BertClassifier(len(self.class_names))\n",
        "    self.classification_model.load_state_dict(torch.load('/content/drive/MyDrive/model/classification.bin'))\n",
        "    self.classification_model = self.classification_model.to(self.device)\n",
        "    self.hmm_tagger_model = dill.load(open('/content/drive/MyDrive/model/tagger_model.dill', 'rb'))\n",
        "    self.similarity_model = torch.load('/content/drive/MyDrive/model/similarity.bin')\n",
        "    self.truth_discovery_model = dill.load(open('/content/drive/MyDrive/model/truth_discovery.dill', 'rb'))\n",
        "    self.idiom_example_df = pd.read_csv(\"/content/idiom-example.csv\")\n",
        "  \n",
        "  def text_preprocessing(self, kalimat, remove_punctuation=False, tokenization=False, lowercase=False):\n",
        "    if (remove_punctuation):\n",
        "      punc = '''!()-[]{};:'\"\\<>/?@#$%^&*_~'''\n",
        "      kalimat = kalimat.translate(str.maketrans('', '', punc))\n",
        "      kalimat = re.sub(r'/s+', ' ', kalimat).strip()\n",
        "    \n",
        "    if (tokenization):\n",
        "      word_punct_tokenizer = WordPunctTokenizer()\n",
        "      kalimat = word_punct_tokenizer.tokenize(kalimat)\n",
        "\n",
        "    if (lowercase):\n",
        "      kalimat = str.lower(kalimat)\n",
        "\n",
        "    return kalimat\n",
        "\n",
        "  def idiom_sentence_classification(self, kalimat):\n",
        "    encoded_text = self.tokenizer.encode_plus(\n",
        "      kalimat,\n",
        "      max_length=40,\n",
        "      add_special_tokens=True,\n",
        "      return_token_type_ids=True,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_text['input_ids'].to(self.device)\n",
        "    attention_mask = encoded_text['attention_mask'].to(self.device)\n",
        "    token_type_ids = encoded_text['token_type_ids'].to(self.device)\n",
        "\n",
        "    output, pred = self.classification_model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "    kategori = self.class_names[pred]\n",
        "\n",
        "    return kategori\n",
        "  \n",
        "  def hasNumbers(self, inputString):\n",
        "    result = False\n",
        "    for char in list(inputString):\n",
        "        if(char.isdigit()):\n",
        "            result = True\n",
        "    return result\n",
        "\n",
        "  def check_tag(self, word, tag):\n",
        "    punc = list(string.punctuation)\n",
        "    punc.append('.')\n",
        "    punc.append(',')\n",
        "    punc.append('\"')\n",
        "    punc.append(\"'\")\n",
        "    \n",
        "    dates = ['Januari','Februari','Maret',\\\n",
        "             'April','Mei','Juni','Juli','Agustus',\\\n",
        "             'September','Oktober','November','Desember',\\\n",
        "            'Jan','Feb','Mar','Apr','Mei',\\\n",
        "             'Jun','Jul','Agt','Sep','Okt','Nov','Des',\\\n",
        "            'januari','februari','maret','april',\\\n",
        "             'mei','juni','juli','agustus',\\\n",
        "             'september','oktober','november','desember',\\\n",
        "            'Senin','Selasa','Rabu','Kamis','Jumat','Sabtu','Minggu'\n",
        "        ]\n",
        "    \n",
        "    if(word in dates):\n",
        "        tag = 'DATE'\n",
        "    \n",
        "    if(word in punc):\n",
        "        tag = 'Z'\n",
        "        \n",
        "    if(tag == 'CD' and word.isdigit()):\n",
        "        tag = 'CD'\n",
        "        \n",
        "    if(tag in ['SYM','Z','CD','MD'] and word.upper() != word and self.hasNumbers(word) == False \\\n",
        "      and word[-3:] not in ['nya','kah','lah']):\n",
        "        tag = 'NNP'\n",
        "    \n",
        "    if(tag == 'NN' and word[:1].upper() == word):\n",
        "        tag = 'NNP'\n",
        "        \n",
        "    if(tag == 'NNP' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "    \n",
        "    if(tag == 'NNP' and len(word) == 1):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    if(tag == 'FW' and word.lower() == word):\n",
        "        tag = 'NN'\n",
        "        \n",
        "    return word, tag\n",
        "\n",
        "  def pos_tagging(self, kalimat):\n",
        "    kalimat_token = self.text_preprocessing(kalimat, tokenization=True)\n",
        "    tagging = self.hmm_tagger_model.tag(kalimat_token)\n",
        "    final_tag = []\n",
        "    for pt in tagging:\n",
        "      w,t = self.check_tag(pt[0], pt[1])\n",
        "      final_tag.append((w,t))\n",
        "\n",
        "    return final_tag\n",
        "\n",
        "  def chunking(self, kalimat_tagged):\n",
        "    grammar = [\"CHUNK: {<NN>{2,}}\", \"CHUNK: {<NN><JJ>}\", \n",
        "               \"CHUNK: {<NN><VB>}\", \"CHUNK: {<CD><NN>}\", \n",
        "               \"CHUNK: {<VB><VB>}\", \"CHUNK: {<VB><NN>}\",\n",
        "               \"CHUNK: {<VB><JJ>}\", \"CHUNK: {<VB><CD>}\",\n",
        "               \"CHUNK: {<JJ><NN>}\", \"CHUNK: {<JJ><JJ>}\"]\n",
        "    \n",
        "    frasa_kandidat = []\n",
        "\n",
        "    for i in grammar:\n",
        "      cp = nltk.RegexpParser(i)\n",
        "      result = cp.parse(kalimat_tagged)\n",
        "\n",
        "      leaves = [chunk.leaves() for chunk in result \\\n",
        "                if ((type(chunk) == nltk.tree.Tree) and \\\n",
        "                    chunk.label() == 'CHUNK')]\n",
        "      bigram_groups = [list(nltk.bigrams([w for w, t in leaf])) \\\n",
        "                       for leaf in leaves]\n",
        "\n",
        "      fr = [' '.join(w) for group in bigram_groups for w in group]\n",
        "      frasa_kandidat = frasa_kandidat + fr\n",
        "\n",
        "    return frasa_kandidat\n",
        "\n",
        "  def count_score_similarity(self, frasa):\n",
        "    token = frasa.split()\n",
        "    similarity_score = self.similarity_model.predict(token[0], token[1])[0][0]\n",
        "\n",
        "    random = self.idiom_example_df.sample(n = 5)\n",
        "    idiom_example = random['idiom_example'].values\n",
        "    \n",
        "    for idiom in idiom_example:\n",
        "      similarity_score = similarity_score + self.similarity_model.predict(frasa, idiom)[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "  def similarity(self, frasa):\n",
        "    frasa_pred = []\n",
        "    if len(frasa) == 0:\n",
        "      frasa_pred = []\n",
        "    else:\n",
        "      for f in frasa:\n",
        "        sim_score = self.count_score_similarity(f)\n",
        "        if sim_score > 0.5:\n",
        "          frasa_pred.append(f)\n",
        "\n",
        "    return frasa_pred\n",
        "\n",
        "  def validasi(self, frasa):\n",
        "    frasa_idiom = []\n",
        "    for f in frasa:\n",
        "      f = self.text_preprocessing(f, lowercase=True)\n",
        "      kategori = self.truth_discovery_model.predict([f])[0]\n",
        "      if kategori == 1:\n",
        "        frasa_idiom.append(f)\n",
        "    \n",
        "    return frasa_idiom\n",
        "\n",
        "  def _predict(self, kalimat):\n",
        "    kalimat = self.text_preprocessing(kalimat, remove_punctuation=True)\n",
        "    klasifikasi = self.idiom_sentence_classification(kalimat)\n",
        "    \n",
        "    if (klasifikasi == 'kalimat_biasa'):\n",
        "      frasa = 'none'\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "    else:\n",
        "      postag = self.pos_tagging(kalimat)\n",
        "      frasa_chunk = self.chunking(postag)\n",
        "      frasa_pred = self.similarity(frasa_chunk)\n",
        "      frasa_idiom = self.validasi(frasa_pred)\n",
        "      if len(frasa_idiom) == 0:\n",
        "        frasa = 'none'\n",
        "      else:\n",
        "        frasa = frasa_idiom[0]\n",
        "      hasil = kalimat, klasifikasi, frasa\n",
        "\n",
        "    return hasil\n",
        "\n",
        "  def predict(self, X):\n",
        "    predicted_result = [self._predict(x) for x in X]\n",
        "    return predicted_result"
      ],
      "metadata": {
        "id": "3Jr4436rjhrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/idiom-ta-kalimat-dataset.csv\", encoding = 'unicode_escape')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "9bxf_ni56YVF",
        "outputId": "530d0ed8-93b9-4414-bbd8-9fe99cceeee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             kalimat       kategori  \\\n",
              "0  Orang tua itu rela membanting tulang demi meny...  kalimat_idiom   \n",
              "1  Rusmi jadi buah bibir setelah menjuarai lomba ...  kalimat_idiom   \n",
              "2  Gara-gara pandemi covid-19 usaha Doyok harus g...  kalimat_idiom   \n",
              "3  Saat pandemi ini Esti harus banting tulang unt...  kalimat_idiom   \n",
              "4  Karena pandemi Covid-19, restoran Pak Hilman a...  kalimat_idiom   \n",
              "\n",
              "         frasa idiom validasi  \\\n",
              "0  membanting tulang    idiom   \n",
              "1         buah bibir    idiom   \n",
              "2       gulung tikar    idiom   \n",
              "3     banting tulang    idiom   \n",
              "4       gulung tikar    idiom   \n",
              "\n",
              "                                              sumber  \n",
              "0  https://tirto.id/pengertian-idiom-dalam-bahasa...  \n",
              "1  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "2  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "3  https://www.medcom.id/pendidikan/news-pendidik...  \n",
              "4  https://xerpihan.id/blog/770/apa-itu-idiom-pen...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd0ad7d6-53f8-4d01-bcf0-68389690029b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kalimat</th>\n",
              "      <th>kategori</th>\n",
              "      <th>frasa idiom</th>\n",
              "      <th>validasi</th>\n",
              "      <th>sumber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Orang tua itu rela membanting tulang demi meny...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>membanting tulang</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://tirto.id/pengertian-idiom-dalam-bahasa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rusmi jadi buah bibir setelah menjuarai lomba ...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>buah bibir</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gara-gara pandemi covid-19 usaha Doyok harus g...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>gulung tikar</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saat pandemi ini Esti harus banting tulang unt...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>banting tulang</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://www.medcom.id/pendidikan/news-pendidik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Karena pandemi Covid-19, restoran Pak Hilman a...</td>\n",
              "      <td>kalimat_idiom</td>\n",
              "      <td>gulung tikar</td>\n",
              "      <td>idiom</td>\n",
              "      <td>https://xerpihan.id/blog/770/apa-itu-idiom-pen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd0ad7d6-53f8-4d01-bcf0-68389690029b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd0ad7d6-53f8-4d01-bcf0-68389690029b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd0ad7d6-53f8-4d01-bcf0-68389690029b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = IdiomIdentification()"
      ],
      "metadata": {
        "id": "_DQjLvlh4u5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PENGUJIAN"
      ],
      "metadata": {
        "id": "p2Jtujo2w9vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "8GT3d2sILgDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "list_n_data = []\n",
        " \n",
        "for n in range(1,11):\n",
        "    list_n_data.append(n*200)\n",
        "\n",
        "acc = []\n",
        "precission = []\n",
        "recall = []\n",
        "f1score = []\n",
        "\n",
        "for n_data in list_n_data:\n",
        "\n",
        "  data = df.sample(n = n_data)\n",
        "  X_kalimat = data['kalimat'].values.tolist()\n",
        "  y_frasa = data['frasa idiom'].values.tolist()\n",
        "  y_validasi = data['validasi'].values.tolist()\n",
        "  y_validasi = [1 if i=='idiom' else 0 for i in y_validasi]\n",
        "\n",
        "  predictions = model.predict(X_kalimat)\n",
        "\n",
        "  idiom_predicted = [predictions[x][2] for x in range(len(predictions))]\n",
        "  y_predicted = ['idiom' if y_frasa[i]==idiom_predicted[i] and idiom_predicted[i]!='none'  else 'bukan_idiom' for i in range(len(idiom_predicted))]\n",
        "  y_predicted = [1 if i=='idiom' else 0 for i in y_predicted]\n",
        "\n",
        "  val_acc = accuracy_score(y_validasi, y_predicted)\n",
        "  acc.append(val_acc)\n",
        "\n",
        "  val_precission = precision_score(y_validasi, y_predicted)\n",
        "  precission.append(val_precission)\n",
        "\n",
        "  val_recall = recall_score(y_validasi, y_predicted)\n",
        "  recall.append(val_recall)\n",
        "\n",
        "  val_f1score = f1_score(y_validasi, y_predicted)\n",
        "  f1score.append(val_f1score)\n",
        "\n",
        "  print('-' * 10)\n",
        "  print(f'jumlah data {n_data}')\n",
        "  print(f'accuracy {val_acc}')\n",
        "  print(f'precission {val_precission}')\n",
        "  print(f'recall {val_recall}')\n",
        "  print(f'f1score {val_f1score}')\n",
        "  print(pd.DataFrame(confusion_matrix(y_validasi, y_predicted), index=label, columns=label))\n",
        "\n",
        "mean_acc = sum(acc) / len(acc)\n",
        "mean_precission = sum(precission) / len(precission)\n",
        "mean_recall = sum(recall) / len(recall)\n",
        "mean_f1score = sum(f1score) / len(f1score)\n",
        "\n",
        "print('-' * 10)\n",
        "print(f\"Mean-Accuracy: {mean_acc}\")\n",
        "print(f\"Mean-Precision: {mean_precission}\")\n",
        "print(f\"Mean-Recall: {mean_recall}\")\n",
        "print(f\"Mean-F1score: {mean_f1score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F-tmIoKw8Kw",
        "outputId": "4fbdc9bc-b21e-47d2-dd1f-8d6655a60244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "jumlah data 200\n",
            "accuracy 0.835\n",
            "precission 1.0\n",
            "recall 0.67\n",
            "f1score 0.8023952095808384\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          100      0\n",
            "idiom                 33     67\n",
            "----------\n",
            "jumlah data 400\n",
            "accuracy 0.8225\n",
            "precission 1.0\n",
            "recall 0.6243386243386243\n",
            "f1score 0.7687296416938111\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          211      0\n",
            "idiom                 71    118\n",
            "----------\n",
            "jumlah data 600\n",
            "accuracy 0.8266666666666667\n",
            "precission 1.0\n",
            "recall 0.6612377850162866\n",
            "f1score 0.7960784313725491\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          293      0\n",
            "idiom                104    203\n",
            "----------\n",
            "jumlah data 800\n",
            "accuracy 0.82375\n",
            "precission 1.0\n",
            "recall 0.6356589147286822\n",
            "f1score 0.7772511848341233\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          413      0\n",
            "idiom                141    246\n",
            "----------\n",
            "jumlah data 1000\n",
            "accuracy 0.822\n",
            "precission 1.0\n",
            "recall 0.6576923076923077\n",
            "f1score 0.7935034802784223\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          480      0\n",
            "idiom                178    342\n",
            "----------\n",
            "jumlah data 1200\n",
            "accuracy 0.8241666666666667\n",
            "precission 1.0\n",
            "recall 0.6495016611295681\n",
            "f1score 0.7875125881168177\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          598      0\n",
            "idiom                211    391\n",
            "----------\n",
            "jumlah data 1400\n",
            "accuracy 0.83\n",
            "precission 1.0\n",
            "recall 0.6619318181818182\n",
            "f1score 0.7965811965811965\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          696      0\n",
            "idiom                238    466\n",
            "----------\n",
            "jumlah data 1600\n",
            "accuracy 0.82375\n",
            "precission 1.0\n",
            "recall 0.6479400749063671\n",
            "f1score 0.7863636363636364\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          799      0\n",
            "idiom                282    519\n",
            "----------\n",
            "jumlah data 1800\n",
            "accuracy 0.8188888888888889\n",
            "precission 1.0\n",
            "recall 0.6425438596491229\n",
            "f1score 0.7823765020026703\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom          888      0\n",
            "idiom                326    586\n",
            "----------\n",
            "jumlah data 2000\n",
            "accuracy 0.821\n",
            "precission 1.0\n",
            "recall 0.642\n",
            "f1score 0.781973203410475\n",
            "             bukan_idiom  idiom\n",
            "bukan_idiom         1000      0\n",
            "idiom                358    642\n",
            "----------\n",
            "Mean-Accuracy: 0.8247722222222222\n",
            "Mean-Precision: 1.0\n",
            "Mean-Recall: 0.6492845045642779\n",
            "Mean-F1score: 0.787276507423454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasl Pengujian"
      ],
      "metadata": {
        "id": "W2b3qwhL9WwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indeks = list(range(1, 11))\n",
        "\n",
        "jml_data_df = pd.DataFrame(list_n_data, index=indeks, columns=['Jumlah Data'])\n",
        "acc_df = pd.DataFrame(acc, index=indeks, columns=['Accuracy'])\n",
        "precission_df = pd.DataFrame(precission, index=indeks, columns=['Precission'])\n",
        "recall_df = pd.DataFrame(recall, index=indeks, columns=['Recall'])\n",
        "f1score_df = pd.DataFrame(f1score, index=indeks, columns=['F1-score'])\n",
        "\n",
        "list_mean = [['', mean_acc, mean_precission, mean_recall, mean_f1score]]\n",
        "mean_df = pd.DataFrame(list_mean,index =['Rata-Rata'], columns =['Jumlah Data','Accuracy','Precission','Recall', 'F1-score'])\n",
        "\n",
        "evaluasi = pd.concat([jml_data_df, acc_df, precission_df, recall_df, f1score_df], axis=1)\n",
        "evaluasi_fix = pd.concat([evaluasi, mean_df], axis=0)\n",
        "evaluasi_fix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JLNNwyO6-nI9",
        "outputId": "59525de8-e6ae-466b-a712-5ef3112a0150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Jumlah Data  Accuracy  Precission    Recall  F1-score\n",
              "1                 200  0.835000         1.0  0.670000  0.802395\n",
              "2                 400  0.822500         1.0  0.624339  0.768730\n",
              "3                 600  0.826667         1.0  0.661238  0.796078\n",
              "4                 800  0.823750         1.0  0.635659  0.777251\n",
              "5                1000  0.822000         1.0  0.657692  0.793503\n",
              "6                1200  0.824167         1.0  0.649502  0.787513\n",
              "7                1400  0.830000         1.0  0.661932  0.796581\n",
              "8                1600  0.823750         1.0  0.647940  0.786364\n",
              "9                1800  0.818889         1.0  0.642544  0.782377\n",
              "10               2000  0.821000         1.0  0.642000  0.781973\n",
              "Rata-Rata              0.824772         1.0  0.649285  0.787277"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1b2c241-1902-4ed8-a767-c8bd8e3a53e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Jumlah Data</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precission</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.802395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>400</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.624339</td>\n",
              "      <td>0.768730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>600</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.661238</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>800</td>\n",
              "      <td>0.823750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635659</td>\n",
              "      <td>0.777251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.657692</td>\n",
              "      <td>0.793503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1200</td>\n",
              "      <td>0.824167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.649502</td>\n",
              "      <td>0.787513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1400</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.661932</td>\n",
              "      <td>0.796581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1600</td>\n",
              "      <td>0.823750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647940</td>\n",
              "      <td>0.786364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1800</td>\n",
              "      <td>0.818889</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.642544</td>\n",
              "      <td>0.782377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2000</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.642000</td>\n",
              "      <td>0.781973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rata-Rata</th>\n",
              "      <td></td>\n",
              "      <td>0.824772</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.649285</td>\n",
              "      <td>0.787277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1b2c241-1902-4ed8-a767-c8bd8e3a53e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1b2c241-1902-4ed8-a767-c8bd8e3a53e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1b2c241-1902-4ed8-a767-c8bd8e3a53e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Raw Text"
      ],
      "metadata": {
        "id": "bViZYSdD9OES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = model.predict(['Andi dikenal sebagai kutu buku.', 'Andi selalu menjadi anak bawang di kelasnya.'])"
      ],
      "metadata": {
        "id": "XE8___J949ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hasil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSyJvTUODZyG",
        "outputId": "79d1605f-0da8-43bf-f3ff-4baf4564f9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Andi dikenal sebagai kutu buku.', 'kalimat_idiom', 'kutu buku'), ('Andi selalu menjadi anak bawang di kelasnya.', 'kalimat_idiom', 'anak bawang')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7NtEcr0P88fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fdQOnrds1Bee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}